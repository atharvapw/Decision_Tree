{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Decision Tree Assignment***\n",
        "\n",
        "\n",
        "\n",
        "1. What is a Decision Tree, and how does it work in classification?\n",
        "* A Decision Tree is a supervised learning algorithm that splits data into branches based on feature values. In classification, it recursively chooses the best feature to divide data into homogeneous groups until leaf nodes represent class labels.\n",
        "\n",
        "2. Explain Gini Impurity and Entropy. How do they impact splits?\n",
        "* Gini Impurity measures how often a randomly chosen sample would be incorrectly labeled. Entropy measures the disorder or uncertainty in a dataset. A decision tree selects splits that minimize impurity—lower Gini or higher Information Gain (entropy reduction).\n",
        "\n",
        "3. Difference between Pre-Pruning and Post-Pruning. One advantage each.\n",
        "* Pre-pruning stops tree growth early by limiting depth or minimum samples, reducing overfitting. Post-pruning grows a full tree first and then removes weak branches, improving generalization and model simplicity.\n",
        "\n",
        "4. What is Information Gain, and why is it important?\n",
        "* Information Gain measures how much uncertainty is reduced after a split. It helps identify the best feature to split on, ensuring the tree becomes more pure and efficient after each split.\n",
        "\n",
        "5. Real-world applications, advantages, and limitations of Decision Trees.\n",
        "* Applications include medical diagnosis, fraud detection, loan approval, and customer segmentation. Trees are easy to interpret and handle mixed data types but tend to overfit and may become unstable with small data changes.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q4peHwFLlHvo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISxuKvTXk51E",
        "outputId": "0bb4d037-3fc8-4c2d-ccef-8e9b40639b43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Feature Importances: [0.         0.01667014 0.90614339 0.07718647]\n"
          ]
        }
      ],
      "source": [
        "# Q6. Write a Python program to:\n",
        "# ● Load the Iris Dataset\n",
        "# ● Train a Decision Tree Classifier using the Gini criterion\n",
        "# ● Print the model’s accuracy and feature importances\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = DecisionTreeClassifier(criterion='gini')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Accuracy & feature importances\n",
        "pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
        "print(\"Feature Importances:\", model.feature_importances_)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q7. Write a Python program to:\n",
        "# ● Load the Iris Dataset\n",
        "# ● Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to a fully-grown tree.\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Full tree\n",
        "full = DecisionTreeClassifier()\n",
        "full.fit(X_train, y_train)\n",
        "full_acc = accuracy_score(y_test, full.predict(X_test))\n",
        "\n",
        "# Depth-limited tree\n",
        "limited = DecisionTreeClassifier(max_depth=3)\n",
        "limited.fit(X_train, y_train)\n",
        "limited_acc = accuracy_score(y_test, limited.predict(X_test))\n",
        "\n",
        "print(\"Fully-grown Tree Accuracy:\", full_acc)\n",
        "print(\"Max Depth = 3 Accuracy:\", limited_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0QGiWhDms45",
        "outputId": "d3a5d7e5-de0d-47a6-d6ee-40017525ec3e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fully-grown Tree Accuracy: 1.0\n",
            "Max Depth = 3 Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q8. Write a Python program to:\n",
        "# ● Load the Boston Housing Dataset\n",
        "# ● Train a Decision Tree Regressor\n",
        "# ● Print the Mean Squared Error (MSE) and feature importances\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "reg = DecisionTreeRegressor()\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Predictions & metrics\n",
        "pred = reg.predict(X_test)\n",
        "print(\"MSE:\", mean_squared_error(y_test, pred))\n",
        "print(\"Feature Importances:\", reg.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUfzN4eRm5e2",
        "outputId": "71867c53-7be0-41d7-b4e5-35aba8341ef3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.5122372264527132\n",
            "Feature Importances: [0.52819451 0.05183078 0.05501545 0.02837502 0.02990242 0.13033425\n",
            " 0.0931787  0.08316887]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q9. Write a Python program to:\n",
        "# ● Load the Iris Dataset\n",
        "# ● Tune the Decision Tree’s max_depth and min_samples_split using GridSearchCV\n",
        "# ● Print the best parameters and the resulting model accuracy\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Parameter grid\n",
        "params = {\n",
        "    'max_depth': [2, 3, 4, 5, None],\n",
        "    'min_samples_split': [2, 3, 4, 5]\n",
        "}\n",
        "\n",
        "# Grid search\n",
        "grid = GridSearchCV(DecisionTreeClassifier(), params, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Results\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "pred = grid.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtpJbfRAnZhA",
        "outputId": "fdc0b007-c227-434f-ca86-79c68b8f3c91"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 4, 'min_samples_split': 2}\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Imagine you’re working as a data scientist for a healthcare company that wants to predict whether a patient has a certain disease. You have a large dataset with mixed data types and some missing values. Explain the step-by-step process you would follow to:\n",
        "\n",
        "● Handle the missing values\n",
        "\n",
        "● Encode the categorical features\n",
        "\n",
        "● Train a Decision Tree model\n",
        "\n",
        "● Tune its hyperparameters\n",
        "\n",
        "● Evaluate its performance And describe what business value this model could provide in the real-world setting.\n",
        "\n",
        "\n",
        "* To handle missing values, use strategies like mean/median imputation for numerics and mode or “most frequent” for categoricals. Encode categorical variables using One-Hot Encoding or Label Encoding depending on model needs. Train a Decision Tree with proper splitting, then optimize max_depth, min_samples_split, etc., using GridSearchCV. Evaluate performance using accuracy, precision, recall, and confusion matrix. Such a model helps hospitals detect diseases early, reduce manual workload, and support faster decision-making."
      ],
      "metadata": {
        "id": "bl0FoB22n93n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7DY3QpYgn9MR"
      }
    }
  ]
}